# HITL-LLM

few keywords: HITL, RLHF, aligning, human feedback, human preference, reasoning, LLM, Transformers

## Human Feedback
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155) 4 Mar 2022

Keyword match: fine-tuning with human-feedback, aligning language models with human intent

- [Aligning Text-to-Image Models using Human Feedback](https://arxiv.org/abs/2302.12192) 23 Feb 2023

Keyword mathch: use the human-labeled image-text dataset to train a reward function that predicts human feedback, aligning such models using human feedback

- [HIVE: Harnessing Human Feedback for Instructional Visual Editing](https://arxiv.org/abs/2303.09618) 16 Mar 2023

Keyword match: harness human feedback for instructional visual editing, introduce scalable diffusion model fine-tuning methods that can incorporate human preferences based on the estimated reward

- [Fine-Grained Human Feedback Gives Better Rewards for Language Model Training](https://arxiv.org/abs/2306.01693) 2 Jun 2023

Keyword match: In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback

- [Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog](https://arxiv.org/abs/1907.00456) 30 Jun 2019

Keyword match: extract multiple different reward functions post-hoc from collected human interaction data, applying RL to real-world problems

- [Pretraining Language Models with Human Preferences](https://arxiv.org/abs/2302.08582) 16 Feb 2023

keyword match: pretraining with human feedback

-------Update at 2023.6.13-----------

- [Languages are Rewards: Chain of Hindsight Finetuning using Human Feedback](https://arxiv.org/pdf/2302.02676.pdf) 25 Mar 2023
- [Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision](https://arxiv.org/pdf/2305.03047.pdf) 4 May 2023
- [RRHF: Rank Responses to Align Language Models with Human Feedback without tears](https://arxiv.org/pdf/2304.05302.pdf) 22 May 2023
- [AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback](https://arxiv.org/pdf/2305.14387.pdf) 22 May 2023
- [Analyzing Influential Factors in Human Preference Judgments via GPT-4](https://arxiv.org/pdf/2305.14702.pdf) 24 May 2023
- [Human-in-the-Loop Interaction for continuously Improving Generative Model in Conversational Agent for Behavioral Intervention](https://dl.acm.org/doi/pdf/10.1145/3581754.3584142) 27 March 2023
- 



HITL related survey:
- [Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation] (https://arxiv.org/pdf/2305.00955.pdf) 1 June 2023




