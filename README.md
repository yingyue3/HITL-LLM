# HITL-LLM

## Human Feedback
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)
Prodecut: InstructGPT
Idea: fine-tuning with human-feedback, aligning language models with human intent


## Human Preference
- [Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog](https://arxiv.org/abs/1907.00456)
